{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NC to CSV\n",
    "\n",
    "*Thomas Bissinger, Hack and Harvest KN, 29.06.24*\n",
    "\n",
    "Turns an .nc file into a .csv file for the heat wave data set. Requires an API key from the climate data store (CDS) *https://cds.climate.copernicus.eu*.\n",
    "\n",
    "The data set can be found under *https://cds.climate.copernicus.eu/cdsapp#!/dataset/sis-heat-and-cold-spells?tab=overview*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q netCDF4\n",
    "%pip install -q pandas\n",
    "%pip install -q wheel\n",
    "%pip install -q cdsapi\n",
    "%pip install -q netCDF4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Download\n",
    "Download the data from the CDS. **API key** needed. This make take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-03 10:14:23,559 INFO Welcome to the CDS\n",
      "2024-07-03 10:14:23,559 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/sis-heat-and-cold-spells\n",
      "2024-07-03 10:14:23,806 INFO Request is queued\n",
      "2024-07-03 10:14:24,878 INFO Request is running\n"
     ]
    }
   ],
   "source": [
    "import cdsapi\n",
    "url = \"https://cds.climate.copernicus.eu/api/v2\"\n",
    "key = \"API KEY HERE\" # insert your API key\n",
    "c = cdsapi.Client()\n",
    "c.retrieve( \n",
    "  'sis-heat-and-cold-spells',\n",
    "  {\n",
    "      'format': 'tgz',\n",
    "      'variable': 'heat_wave_days',\n",
    "      'definition': 'climatological_related',\n",
    "      'experiment': [\n",
    "          'rcp4_5', 'rcp8_5',\n",
    "      ],\n",
    "      'ensemble_statistic': [\n",
    "          'ensemble_members_average', 'ensemble_members_standard_deviation',\n",
    "      ],\n",
    "  },\n",
    "  'download.tar.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Read a single .nc file\n",
    "Get to know the values stored in a .nc file. You have to extract the archive downloaded in the previous step into some datafolder.\n",
    "This function reads out a specific file and shows the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable names and dimensions the NetCDF file:\n",
      "variable name        |      dim 1 |      dim 2 |      dim 3\n",
      "-------------------------------------------------------------------\n",
      "height               |          1 |          1 |          1\n",
      "quantile             |          1 |          1 |          1\n",
      "lat                  |        425 |          1 |          1\n",
      "lon                  |        599 |          1 |          1\n",
      "time                 |        100 |          1 |          1\n",
      "HWD_EU_climate       |        100 |        425 |        599\n"
     ]
    }
   ],
   "source": [
    "import netCDF4 as nc\n",
    "\n",
    "# Make your change here\n",
    "datafolder='C:/Users/Thomas/OneDrive/Programming/2024_HackAndHarvestKN/data' \n",
    "filename='HWD_EU_climate_rcp85_mean_v1.0.nc'\n",
    "filename='HWD_EU_climate_rcp85_stdev_v1.0.nc'\n",
    "filepath = datafolder + '/' + filename\n",
    "# Open NetCDF file\n",
    "netcdf_file = nc.Dataset(filepath, 'r')\n",
    "\n",
    "\n",
    "variable_names = list(netcdf_file.variables.keys())\n",
    "\n",
    "# Print variable names\n",
    "print(\"Variable names and dimensions the NetCDF file:\")\n",
    "\n",
    "\n",
    "print(\"{:<20} | {:>10} | {:>10} | {:>10}\".format(\"variable name\", \"dim 1\", \"dim 2\", \"dim 3\"))\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "for name in variable_names:\n",
    "    data = netcdf_file.variables[name][:]\n",
    "    try:\n",
    "        dim_1 = len(data)\n",
    "    except TypeError:\n",
    "        dim_1 = 1\n",
    "    try:\n",
    "        dim_2 = len(data[0])\n",
    "    except TypeError:\n",
    "        dim_2 = 1\n",
    "    except IndexError:\n",
    "        dim_2 = 1\n",
    "    try:\n",
    "        dim_3 = len(data[0][0])\n",
    "    except TypeError:\n",
    "        dim_3 = 1\n",
    "    except IndexError:\n",
    "        dim_3 = 1\n",
    "    print(\"{:<20} | {:>10} | {:>10} | {:>10}\".format(name, dim_1, dim_2,dim_3))\n",
    "\n",
    "#print(\"A closer look at the variables:\")\n",
    "#for name in variable_names:\n",
    "#    data = netcdf_file.variables[name][:]\n",
    "#    print(\"  \", name, data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Extract time series information about a single pixel\n",
    "Create an auxiliary function to extract time series data for a single pixel, then a routine that realizes that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the routine\n",
    "The routine gets a latitude and a longitude as input, the path to the nc file and the variable name that stores the relevant information. It computes the relevant index on the fly (so far, the step length has to be manually included as cells in the latitude-longitude grid are identified by their northeast corner, yet indexed with reference to the southwesternmost point in the domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc\n",
    "def PixelToTimeSeries(latitude, longitude, ncpath, varname):\n",
    "    steplength = 0.1\n",
    "    netcdf_file = nc.Dataset(ncpath, 'r')\n",
    "    lat_start = netcdf_file.variables[\"lat\"][0] - steplength\n",
    "    lon_start = netcdf_file.variables[\"lon\"][0] - steplength\n",
    "    lat_ind = int(( latitude - lat_start ) / steplength)\n",
    "    lon_ind = int(( longitude - lon_start ) / steplength)\n",
    "    return netcdf_file.variables[varname][:,lat_ind,lon_ind] # Assumes data format of varname to be time x lat x lon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting information\n",
    "Now we take everything we found so far and extract two .csv files for a single city. Adjustments for the inclusion of additional pixels can be made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to C:/Users/Thomas/OneDrive/Programming/2024_HackAndHarvestKN/data/data_rcp45.csv\n",
      "Data written to C:/Users/Thomas/OneDrive/Programming/2024_HackAndHarvestKN/data/data_rcp85.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "varname = 'HWD_EU_climate' \n",
    "latitude = 47.66 # For Konstanz\n",
    "longitude = 9.17 # For Konstanz\n",
    "datadir = 'C:/Users/Thomas/OneDrive/Programming/2024_HackAndHarvestKN/data' \n",
    "prefix = 'HWD_EU_climate'\n",
    "mean_suffix = 'mean_v1.0.nc'\n",
    "stdev_suffix = 'stdev_v1.0.nc'\n",
    "for rcp_choice in [4.5, 8.5]:\n",
    "    if rcp_choice == 4.5:\n",
    "        modelname = 'rcp45'\n",
    "        modelname_full = 'RCP4.5'\n",
    "    elif rcp_choice == 8.5:\n",
    "        modelname = 'rcp85'\n",
    "        modelname_full = 'RCP8.5'\n",
    "    mean_filepath = datadir + '/' + prefix + '_' + modelname + '_' + mean_suffix\n",
    "    stdev_filepath = datadir + '/' + prefix + '_' + modelname + '_' + stdev_suffix\n",
    "    csvfile_path = datadir + '/' + 'data_' + modelname + '.csv'\n",
    "    start_year = 1986\n",
    "    \n",
    "    \n",
    "    # Load the heat_days into a numpy array\n",
    "    heat_days = PixelToTimeSeries(latitude, longitude, mean_filepath, varname)\n",
    "    heat_days_std = PixelToTimeSeries(latitude, longitude, stdev_filepath, varname)\n",
    "    date_vals = np.arange(start_year,start_year + heat_days.size)\n",
    "    # Write to a CSV file\n",
    "    with open(csvfile_path, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        # Writing the header (optional)\n",
    "        writer.writerow(['date', 'heat days', 'heat days std'])\n",
    "        # Writing the heat_days rows\n",
    "        for i in range(len(date_vals)):\n",
    "            writer.writerow([date_vals[i], heat_days[i],heat_days_std[i]])\n",
    "\n",
    "    print(\"Data written to \" + csvfile_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
